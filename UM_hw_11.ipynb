{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChecinskiBartlomiej/UM/blob/main/UM_hw_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework Assignment: Understanding Deconvolution in Autoencoders**\n",
        "---------------\n",
        "\n",
        "In class, we worked with autoencoders built from multilayer perceptrons (MLPs). However, encoders are often constructed using convolutional architectures to better capture spatial patterns. In this assignment, you'll explore how the decoder can use deconvolutional (transposed convolution) layers to reverse and mirror the operations performed by the convolutional encoder.\n",
        "\n",
        "While convolutional encoders are relatively well understood, **decoding (or upsampling) the compressed representation** using **deconvolutional layers** (also known as **transposed convolutions**) often raises questions.\n",
        "\n",
        "This assignment is particularly relevant because deconvolution is a core component of the U-Net architecture, a prominent neural network used extensively in image segmentation tasks.\n",
        "\n",
        "Your main objective is to deeply understand **how transposed convolution layers work**, and explain them in both words and visuals.\n",
        "\n",
        "\n",
        "## **The Objective**\n",
        "\n",
        "Understand and clearly explain how **transposed convolutions** work. Use 2D transposed convolutions and a small grid of 2D points as a working example.\n",
        "\n",
        "You may need to do some additional reading to complete this assignment.\n",
        "\n",
        "## **Tasks & Deliverables**\n",
        "\n",
        "### 1. **Theory Exploration**\n",
        "\n",
        "Using markdown cells in your Colab notebook, answer the following:\n",
        "\n",
        "- What is a **transposed convolution**?\n",
        "- How does it differ from a regular convolution?\n",
        "- How does it upsample feature maps?\n",
        "- What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?\n",
        "- To earn full two points, your explanation must be detailed enough for a reader to reproduce the upsampling process step by step.\n",
        "\n",
        "\n",
        "### 2. **Manual Diagram (by your hand, not a generated image)**\n",
        "\n",
        "Carefully plan and draw **by hand** a diagram or a set of diagrams that:\n",
        "\n",
        "- Explain the process of using **transposed convolution**.\n",
        "- Use an example of a **small input grid of 2D points** which gets expanded into a larger output grid.\n",
        "- Explain how stride, padding, and the kernel shape affect the result.\n",
        "- Show intermediate steps of the operation, not just input and output.\n",
        "\n",
        "**Scan or photograph your diagram(s)**, and upload it to your **GitHub repository** for this course.\n",
        "\n",
        "Then embed it in your Colab notebook using markdown (you can find examples on *how to do it* in previous notebooks related to this class, e.g. the one on linear regression or the one on the MLP network).\n",
        "\n",
        "\n",
        "### 3. **Publish on GitHub**  \n",
        "   - Place the Colab notebook in your **GitHub repository** for this course.\n",
        "   - In your repository’s **README**, add a **link** to the notebook and also include an **“Open in Colab”** badge at the top of the notebook so it can be launched directly from GitHub.\n"
      ],
      "metadata": {
        "id": "4Ar3Nf6gOX4Y"
      },
      "id": "4Ar3Nf6gOX4Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Transposed convolution is a neural network layer—often used in decoders—that performs learnable upsampling. Given a smaller feature map (for example, a compressed image produced by earlier convolutional layers) it produces a larger output. In doing so, it learns how to reconstruct finer spatial details that were lost during downsampling.\n",
        "\n",
        "2.Regular convolution most often downsample image, meaning it outputs smaller matrix which is compression of input. In contrast, transposed convolution make output bigger than input.\n",
        "\n",
        "3.There are a few methods to demonstrate general concept of how is upsampling performed. I like the one with transposed matrix.\n",
        "\n",
        "Regular convolution can be written as matrix multiplication, in particular multiplication of matrix $M$ which is created based on kernel and vector $I$ which is created based on input.\n",
        "\n",
        "Column vector $I$ is just stacked rows of input matrix on top of each other. Creation of $M$ is more subtle. It is wide and sparse matrix filled with kernel's matrix entries. Each row is responsible for one output node or one slide of kernel.\n",
        "\n",
        "I believe that the easiest way to grasp this process is by examining the numerical example below, rather than by studying the general mathematical description. The concept is easy but formalization include lots of indices and can be intimidating.\n",
        "\n",
        "4.Just as in regular convolution these are hyperparameters. Again, I think the best way to understand them is by looking at example, but let's discuss them on the high level.\n",
        "\n",
        "Kernel size is responsible for the receptive field. A larger kernel spreads each input pixel's influence over more output positions.\n",
        "\n",
        "As shown in the example below, a transposed convolution can likewise be viewed as sliding a kernel over the input. The stride, just as in a standard convolution determines how far the kernel moves with each step.\n",
        "\n",
        "Padding specifies how many rows and columns to remove: columns are cropped on the left and right, and rows on the top and bottom."
      ],
      "metadata": {
        "id": "nprzV5F8AAki"
      },
      "id": "nprzV5F8AAki"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/ChecinskiBartlomiej/UM/blob/main/transposed_convolution1.png?raw=1\" alt=\"transposed convolution\" width=\"400\" height=\"400\">"
      ],
      "metadata": {
        "id": "xTscHqXOoiCk"
      },
      "id": "xTscHqXOoiCk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/ChecinskiBartlomiej/UM/blob/main/transposed_convolution2.png?raw=1\" alt=\"transposed convolution\" width=\"400\" height=\"400\">"
      ],
      "metadata": {
        "id": "_iznpJhepbUp"
      },
      "id": "_iznpJhepbUp"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}